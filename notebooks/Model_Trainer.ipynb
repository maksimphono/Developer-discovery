{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "455cc887-8373-451d-8c96-a66b7530486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/trukhinmaksim/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac85e37c-719b-47b1-ad1d-d30439b5de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbb769a8-0ff3-4600-a09e-c7000d01df34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(Database(MongoClient(host=['172.26.234.237:27020'], document_class=dict, tz_aware=False, connect=True), 'mini_database'), 'projects')\n"
     ]
    }
   ],
   "source": [
    "from src.utils.DatabaseConnect import DatabaseConnect\n",
    "\n",
    "# single machine setup (mongo is running here localy)\n",
    "# \"ip a\" for ip address\n",
    "MY_DATABASE_LINK = 'mongodb://172.26.234.237:27020/' #'mongodb://192.168.100.57:27020/'\n",
    "# multiple mechine setup (mongo is running on another machine)\n",
    "#MY_DATABASE_LINK = 'mongodb://192.168.43.78:27020/'\n",
    "\n",
    "DatabaseConnect.DB_LINK = MY_DATABASE_LINK\n",
    "\n",
    "projectsCollection = DatabaseConnect.mini_database.projects()\n",
    "usersCollection = DatabaseConnect.mini_database.users()\n",
    "print(projectsCollection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b374dd4-9b71-43d2-8770-d21b16bcc9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.CacheAdapter import JSONAdapter, JSONMultiFileAdapter, EXP_END_OF_DATA\n",
    "from src.utils.DatasetManager import ProjectsDatasetManager\n",
    "from src.utils.validators import projectDataIsSufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5efae60e-04ba-4278-816a-35a98e781082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatternData(data : dict[str, list]) -> np.array(dict):\n",
    "    # takes in data in form of dict, where each key is a user id and each value is a list of that user's projects\n",
    "    # returns just flat list of these projects \n",
    "    result = []\n",
    "\n",
    "    for projectsArray in data.values():\n",
    "        for project in projectsArray:\n",
    "            result.append(project)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58adadd7-d7f4-427c-a97d-8720bbaf1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b772eb3-0407-4b1a-84ea-66c9710f9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_FILE_NAME = \"cache__31-03-2025__(sufficient)_{index}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39bb961c-3354-44d7-b365-b364502962bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using adapter to load data from the cache files\n",
    "\n",
    "class DataFeeder(ProjectsDatasetManager):\n",
    "    def __init__(self, batchSize = 32):\n",
    "        #super().__init__(batchSize, validator, adapter)\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def feedFromCache(self, cacheAdapter):\n",
    "        # generator function, that will use \"JSONMultifileAdapter\" to parse data from multiple cache file, collect projects into a list and feed to the model\n",
    "        tempStorage = []\n",
    "        #self.cacheAdapter = cacheAdapter\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            try:\n",
    "                while len(tempStorage) >= self.batchSize:\n",
    "                    yield tempStorage[:self.batchSize]\n",
    "                    tempStorage = tempStorage[self.batchSize:]\n",
    "\n",
    "                data = cacheAdapter.load(1) # load users one by one\n",
    "                data = flatternData(data)\n",
    "                tempStorage.extend(data)\n",
    "\n",
    "                i += 1\n",
    "\n",
    "            except EXP_END_OF_DATA:\n",
    "                break\n",
    "\n",
    "        yield tempStorage\n",
    "\n",
    "def feedProjectsFromCache(manager, batchSize = 32):\n",
    "    cacheFileName = CACHE_FILE_NAME\n",
    "    tempStorage = []\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            while len(tempStorage) >= batchSize:\n",
    "                yield tempStorage[:batchSize]\n",
    "                tempStorage = tempStorage[batchSize:]\n",
    "\n",
    "            manager.cacheAdapter.collectionName = cacheFileName.format(index = i)\n",
    "            data = flatternData(manager.fromCache())\n",
    "            tempStorage.extend(data)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        except EXP_END_OF_DATA:\n",
    "            # no data left\n",
    "            break\n",
    "\n",
    "    yield tempStorage\n",
    "\n",
    "class Corpus:\n",
    "    # base class for every data corpus, that will be used by model\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __iter__(self):\n",
    "        pass\n",
    "    def __getitem__(self, index : int):\n",
    "        pass\n",
    "\n",
    "class CacheCorpus(Corpus):\n",
    "    def __init__(self, manager, cacheFileNameTemplate = CACHE_FILE_NAME):\n",
    "        self.cacheFileNameTemplate = cacheFileNameTemplate\n",
    "        self.manager = manager\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # will feed preprocessed projects data as TaggedDocument instances one by one\n",
    "        cacheFileName = self.cacheFileNameTemplate\n",
    "        tempStorage = [] # temporary storage for data, that was read from files\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            try:\n",
    "                while len(tempStorage) >= 1:\n",
    "                    doc = tempStorage[0]\n",
    "                    yield TaggedDocument(words = doc[\"tokens\"], tags = doc[\"tags\"])\n",
    "                    tempStorage = tempStorage[1:]\n",
    "\n",
    "                self.manager.cacheAdapter.collectionName = cacheFileName.format(index = i)\n",
    "                data = flatternData(self.manager.fromCache())\n",
    "                tempStorage.extend(data)\n",
    "\n",
    "                i += 1\n",
    "\n",
    "            except EXP_END_OF_DATA:\n",
    "            # no data left\n",
    "                break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "584ed1f5-c3a9-4aa4-8368-22fec165fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = JSONAdapter()\n",
    "ProjectsDatasetManager.usersCollection = usersCollection\n",
    "ProjectsDatasetManager.projectsCollection = projectsCollection\n",
    "manager = ProjectsDatasetManager(25, validate = projectDataIsSufficient, cacheAdapter = adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d2375ea-9300-497e-882a-ce5ca7010e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "manager.fromDB()\n",
    "textData = manager.getTextOnly()\n",
    "for text in flatternData(textData):\n",
    "    print(text)\n",
    "    #print(flatternData(data))\n",
    "    #print(text)\n",
    "\"\"\"\n",
    "def feedTextData(manager, batchSize = 1):\n",
    "    # feeds text data by batches\n",
    "    tempStorage = []\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            while len(tempStorage) >= batchSize:\n",
    "                if batchSize > 1:\n",
    "                    yield tempStorage[:batchSize]\n",
    "                else:\n",
    "                    yield tempStorage[:batchSize][0] # if I'm requesting only one item per time (training one by one) -> just yield it\n",
    "                tempStorage = tempStorage[batchSize:]\n",
    "\n",
    "            manager.fromDB()\n",
    "            data = flatternData(manager.getTextOnly())\n",
    "            tempStorage.extend(data)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        except EXP_END_OF_DATA:\n",
    "            break\n",
    "\n",
    "    yield tempStorage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb02703b-a50b-44f5-9845-a3e5a7b451fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ni = 2\\ncorp = CacheCorpus(manager)\\nfor item in corp:\\n    if i == 0: break\\n    print(item)\\n    i -= 1\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "i = 2\n",
    "corp = CacheCorpus(manager)\n",
    "for item in corp:\n",
    "    if i == 0: break\n",
    "    print(item)\n",
    "    i -= 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f5f4d69-6c5e-432d-91fc-d1573f105b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXP_FEEDER_IS_NONE(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"'Model.corpus' object must be an iterable structure, inherited from 'Corpus' class!\")\n",
    "\n",
    "class EXP_MANAGER_IS_NONE(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"'Model.manager' object must be a DatasetManager instance!\")\n",
    "\n",
    "\n",
    "class Model(gensim.models.doc2vec.Doc2Vec):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.corpus = None # corpus is an iterator(iterable class object), that will be used in \"train\" method of Doc2Vec model for data extraction\n",
    "        self.manager = None\n",
    "    \n",
    "    def train(self):\n",
    "        # will build vocabulary and train the model on corpus (corpus will be fed by corpus)\n",
    "        import logging\n",
    "        logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "        \n",
    "        if not isinstance(self.corpus, Corpus): raise EXP_FEEDER_IS_NONE\n",
    "        #if not isinstance(self.manager, ProjectsDatasetManager) : raise EXP_MANAGER_IS_NONE\n",
    "\n",
    "        self.build_vocab(self.corpus)\n",
    "\n",
    "        super().train(self.corpus, total_examples=self.corpus_count, epochs=self.epochs)\n",
    "\n",
    "    def assess(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82a60326-ef2e-46e5-b3bc-15f192b58925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndocumentsCorpus = []\\n\\nfor project in manager.data:\\n    documentsCorpus.append(TaggedDocument(words=project[\"tokens\"], tags=project[\"tags\"]))\\n\\ndocumentsCorpus\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "documentsCorpus = []\n",
    "\n",
    "for project in manager.data:\n",
    "    documentsCorpus.append(TaggedDocument(words=project[\"tokens\"], tags=project[\"tags\"]))\n",
    "\n",
    "documentsCorpus\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9150ae5-5a1a-4edb-be81-93c16fa102be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 08:24:48,050 : INFO : collecting all words and their counts\n",
      "2025-04-02 08:24:48,055 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2025-04-02 08:24:48,275 : INFO : PROGRESS: at example #10000, processed 90782 words (414567 words/s), 12220 word types, 24596 tags\n",
      "2025-04-02 08:24:48,691 : WARNING : More unique tags (46575) than documents (19852).\n",
      "2025-04-02 08:24:48,991 : INFO : collected 20813 word types and 46575 unique tags from a corpus of 19852 examples and 178966 words\n",
      "2025-04-02 08:24:48,993 : INFO : Creating a fresh vocabulary\n",
      "2025-04-02 08:24:49,033 : INFO : Model lifecycle event {'msg': 'effective_min_count=3 retains 6256 unique words (30.06% of original 20813, drops 14557)', 'datetime': '2025-04-02T08:24:49.033606', 'gensim': '4.3.3', 'python': '3.11.11 (main, Feb  4 2025, 07:29:35) [GCC 12.2.0]', 'platform': 'Linux-6.13.8-200.fc41.x86_64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}\n",
      "2025-04-02 08:24:49,035 : INFO : Model lifecycle event {'msg': 'effective_min_count=3 leaves 160718 word corpus (89.80% of original 178966, drops 18248)', 'datetime': '2025-04-02T08:24:49.035207', 'gensim': '4.3.3', 'python': '3.11.11 (main, Feb  4 2025, 07:29:35) [GCC 12.2.0]', 'platform': 'Linux-6.13.8-200.fc41.x86_64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}\n",
      "2025-04-02 08:24:49,094 : INFO : deleting the raw counts dictionary of 20813 items\n",
      "2025-04-02 08:24:49,097 : INFO : sample=0.001 downsamples 39 most-common words\n",
      "2025-04-02 08:24:49,099 : INFO : Model lifecycle event {'msg': 'downsampling leaves estimated 143677.63628101844 word corpus (89.4%% of prior 160718)', 'datetime': '2025-04-02T08:24:49.098983', 'gensim': '4.3.3', 'python': '3.11.11 (main, Feb  4 2025, 07:29:35) [GCC 12.2.0]', 'platform': 'Linux-6.13.8-200.fc41.x86_64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}\n",
      "2025-04-02 08:24:49,189 : INFO : estimated required memory for 6256 words and 100 dimensions: 36077800 bytes\n",
      "2025-04-02 08:24:49,191 : INFO : resetting layer weights\n",
      "2025-04-02 08:24:49,242 : INFO : Model lifecycle event {'msg': 'training model with 3 workers on 6256 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2025-04-02T08:24:49.242082', 'gensim': '4.3.3', 'python': '3.11.11 (main, Feb  4 2025, 07:29:35) [GCC 12.2.0]', 'platform': 'Linux-6.13.8-200.fc41.x86_64-x86_64-with-glibc2.36', 'event': 'train'}\n",
      "2025-04-02 08:24:50,303 : INFO : EPOCH 0 - PROGRESS: at 27.97% examples, 64968 words/s, in_qsize 6, out_qsize 0\n",
      "2025-04-02 08:24:51,524 : INFO : EPOCH 0 - PROGRESS: at 72.02% examples, 77980 words/s, in_qsize 5, out_qsize 0\n",
      "2025-04-02 08:24:52,059 : INFO : EPOCH 0: training on 178966 raw words (246596 effective words) took 2.8s, 87632 effective words/s\n",
      "2025-04-02 08:24:53,240 : INFO : EPOCH 1 - PROGRESS: at 21.72% examples, 46560 words/s, in_qsize 6, out_qsize 0\n",
      "2025-04-02 08:24:54,253 : INFO : EPOCH 1 - PROGRESS: at 60.69% examples, 68685 words/s, in_qsize 6, out_qsize 0\n",
      "2025-04-02 08:24:55,039 : INFO : EPOCH 1: training on 178966 raw words (246657 effective words) took 3.0s, 82897 effective words/s\n",
      "2025-04-02 08:24:56,289 : INFO : EPOCH 2 - PROGRESS: at 27.06% examples, 54792 words/s, in_qsize 5, out_qsize 0\n",
      "2025-04-02 08:24:57,583 : INFO : EPOCH 2 - PROGRESS: at 72.02% examples, 69920 words/s, in_qsize 5, out_qsize 0\n",
      "2025-04-02 08:24:58,037 : INFO : EPOCH 2: training on 178966 raw words (246569 effective words) took 3.0s, 82334 effective words/s\n",
      "2025-04-02 08:24:59,053 : INFO : EPOCH 3 - PROGRESS: at 32.72% examples, 80708 words/s, in_qsize 6, out_qsize 0\n",
      "2025-04-02 08:25:00,282 : INFO : EPOCH 3 - PROGRESS: at 71.89% examples, 79075 words/s, in_qsize 5, out_qsize 0\n",
      "2025-04-02 08:25:00,675 : INFO : EPOCH 3: training on 178966 raw words (246613 effective words) took 2.6s, 93584 effective words/s\n",
      "2025-04-02 08:25:01,908 : INFO : EPOCH 4 - PROGRESS: at 22.31% examples, 44887 words/s, in_qsize 5, out_qsize 0\n",
      "2025-04-02 08:25:03,231 : INFO : EPOCH 4 - PROGRESS: at 71.89% examples, 69456 words/s, in_qsize 5, out_qsize 0\n",
      "2025-04-02 08:25:03,623 : INFO : EPOCH 4: training on 178966 raw words (246520 effective words) took 2.9s, 83744 effective words/s\n",
      "2025-04-02 08:25:04,629 : INFO : EPOCH 5 - PROGRESS: at 21.72% examples, 54626 words/s, in_qsize 6, out_qsize 0\n",
      "2025-04-02 08:25:05,642 : INFO : EPOCH 5 - PROGRESS: at 60.69% examples, 74564 words/s, in_qsize 5, out_qsize 0\n",
      "2025-04-02 08:25:06,415 : INFO : EPOCH 5: training on 178966 raw words (246503 effective words) took 2.8s, 88388 effective words/s\n",
      "2025-04-02 08:25:07,640 : INFO : EPOCH 6 - PROGRESS: at 21.72% examples, 44874 words/s, in_qsize 6, out_qsize 0\n",
      "2025-04-02 08:25:08,942 : INFO : EPOCH 6 - PROGRESS: at 72.02% examples, 70435 words/s, in_qsize 5, out_qsize 0\n",
      "2025-04-02 08:25:09,324 : INFO : EPOCH 6: training on 178966 raw words (246549 effective words) took 2.9s, 84872 effective words/s\n",
      "2025-04-02 08:25:10,590 : INFO : EPOCH 7 - PROGRESS: at 22.63% examples, 43655 words/s, in_qsize 5, out_qsize 0\n",
      "2025-04-02 08:25:11,700 : INFO : EPOCH 7 - PROGRESS: at 66.25% examples, 69031 words/s, in_qsize 5, out_qsize 0\n",
      "2025-04-02 08:25:12,476 : INFO : EPOCH 7: training on 178966 raw words (246520 effective words) took 3.1s, 78297 effective words/s\n",
      "2025-04-02 08:25:13,505 : INFO : EPOCH 8 - PROGRESS: at 32.72% examples, 79941 words/s, in_qsize 6, out_qsize 0\n",
      "2025-04-02 08:25:14,733 : INFO : EPOCH 8 - PROGRESS: at 72.02% examples, 78857 words/s, in_qsize 5, out_qsize 0\n",
      "2025-04-02 08:25:15,141 : INFO : EPOCH 8: training on 178966 raw words (246540 effective words) took 2.7s, 92692 effective words/s\n",
      "2025-04-02 08:25:16,362 : INFO : EPOCH 9 - PROGRESS: at 21.72% examples, 45034 words/s, in_qsize 5, out_qsize 0\n",
      "2025-04-02 08:25:17,374 : INFO : EPOCH 9 - PROGRESS: at 66.25% examples, 73467 words/s, in_qsize 6, out_qsize 0\n",
      "2025-04-02 08:25:18,161 : INFO : EPOCH 9: training on 178966 raw words (246436 effective words) took 3.0s, 81726 effective words/s\n",
      "2025-04-02 08:25:18,163 : INFO : Model lifecycle event {'msg': 'training on 1789660 raw words (2465503 effective words) took 28.9s, 85254 effective words/s', 'datetime': '2025-04-02T08:25:18.163066', 'gensim': '4.3.3', 'python': '3.11.11 (main, Feb  4 2025, 07:29:35) [GCC 12.2.0]', 'platform': 'Linux-6.13.8-200.fc41.x86_64-x86_64-with-glibc2.36', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "\n",
    "VECTOR_SIZE = 100\n",
    "EPOCH_NUMBER = 10\n",
    "WORD_MIN_AMOUNT = 3\n",
    "WINDOW_SIZE = 7\n",
    "\n",
    "model = Model(vector_size = VECTOR_SIZE, window = WINDOW_SIZE, min_count = WORD_MIN_AMOUNT, epochs = EPOCH_NUMBER)\n",
    "model.corpus = CacheCorpus(manager)\n",
    "model.train()\n",
    "print(model.epochs)\n",
    "#model.build_vocab(documentsCorpus)\n",
    "#model.train(documentsCorpus, total_examples = model.corpus_count, epochs = model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01ab2f6a-599d-4f6d-9a52-ef8ff174f113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00308863, -0.00735241, -0.02905755, -0.00087031, -0.01099693,\n",
       "        0.02082823,  0.02023694, -0.00334258, -0.00799487, -0.00433645,\n",
       "       -0.02051825,  0.00601316, -0.00980301,  0.01860038,  0.03266804,\n",
       "       -0.0304384 ,  0.00677712, -0.03670615,  0.01083722, -0.02049837,\n",
       "        0.00231234, -0.00871367,  0.00825047,  0.01820921,  0.00338148,\n",
       "        0.00953344, -0.01728403, -0.0047023 , -0.04001134,  0.004596  ,\n",
       "       -0.0296433 ,  0.01734056,  0.023515  ,  0.02000066, -0.02267226,\n",
       "        0.01982907,  0.03472478, -0.0253478 ,  0.00523992, -0.02408287,\n",
       "        0.02872182,  0.00134164, -0.02194417,  0.02691794, -0.03505132,\n",
       "        0.00605899, -0.00352153, -0.00400082,  0.02695579,  0.0387282 ,\n",
       "       -0.02189158, -0.00072087, -0.00812104,  0.00809368, -0.01303041,\n",
       "       -0.01916484, -0.01470063, -0.00090048, -0.03214884,  0.00935926,\n",
       "        0.00322564, -0.01434393, -0.00888153, -0.00861587, -0.02469372,\n",
       "        0.02592297,  0.0189695 ,  0.0325394 ,  0.01361089,  0.01780326,\n",
       "        0.00905733,  0.02712038, -0.00717759, -0.01374094,  0.01968522,\n",
       "        0.0294132 ,  0.03551762, -0.02435201, -0.01330741, -0.00721628,\n",
       "       -0.01434908,  0.01355008, -0.00264941,  0.01061987, -0.02874485,\n",
       "        0.02750448,  0.02337601, -0.01290772, -0.02496004,  0.01032119,\n",
       "        0.00658726,  0.00240194,  0.01938117, -0.00443399,  0.02338659,\n",
       "        0.01881839, -0.04192955,  0.00098451,  0.0070555 , -0.03183013],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vector = model.infer_vector(['awesome', 'code', 'streamer', 'list', 'code', 'streamer', 'multiple', 'plataforms', 'like', 'twitch', 'youtube'])\n",
    "vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
