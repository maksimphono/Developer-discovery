{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "455cc887-8373-451d-8c96-a66b7530486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/trukhinmaksim/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac85e37c-719b-47b1-ad1d-d30439b5de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbb769a8-0ff3-4600-a09e-c7000d01df34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(Database(MongoClient(host=['172.26.234.237:27020'], document_class=dict, tz_aware=False, connect=True), 'mini_database'), 'projects')\n"
     ]
    }
   ],
   "source": [
    "from src.utils.DatabaseConnect import DatabaseConnect\n",
    "\n",
    "# single machine setup (mongo is running here localy)\n",
    "# \"ip a\" for ip address\n",
    "MY_DATABASE_LINK = 'mongodb://172.26.234.237:27020/' #'mongodb://192.168.100.57:27020/'\n",
    "# multiple mechine setup (mongo is running on another machine)\n",
    "#MY_DATABASE_LINK = 'mongodb://192.168.43.78:27020/'\n",
    "\n",
    "DatabaseConnect.DB_LINK = MY_DATABASE_LINK\n",
    "\n",
    "projectsCollection = DatabaseConnect.mini_database.projects()\n",
    "usersCollection = DatabaseConnect.mini_database.users()\n",
    "print(projectsCollection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b374dd4-9b71-43d2-8770-d21b16bcc9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.CacheAdapter import JSONAdapter, JSONMultiFileAdapter, EXP_END_OF_DATA\n",
    "from src.utils.DatasetManager import ProjectsDatasetManager\n",
    "from src.utils.validators import projectDataIsSufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5efae60e-04ba-4278-816a-35a98e781082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatternData(data : dict[str, list]) -> np.array(dict):\n",
    "    # takes in data in form of dict, where each key is a user id and each value is a list of that user's projects\n",
    "    # returns just flat list of these projects \n",
    "    result = []\n",
    "\n",
    "    for projectsArray in data.values():\n",
    "        for project in projectsArray:\n",
    "            result.append(project)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58adadd7-d7f4-427c-a97d-8720bbaf1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b772eb3-0407-4b1a-84ea-66c9710f9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_FILE_NAME = \"cache__31-03-2025__(sufficient)_{index}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39bb961c-3354-44d7-b365-b364502962bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using adapter to load data from the cache files\n",
    "\n",
    "class DataFeeder(ProjectsDatasetManager):\n",
    "    def __init__(self, batchSize = 32):\n",
    "        #super().__init__(batchSize, validator, adapter)\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def feedFromCache(self, cacheAdapter):\n",
    "        # generator function, that will use \"JSONMultifileAdapter\" to parse data from multiple cache file, collect projects into a list and feed to the model\n",
    "        tempStorage = []\n",
    "        #self.cacheAdapter = cacheAdapter\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            try:\n",
    "                while len(tempStorage) >= self.batchSize:\n",
    "                    yield tempStorage[:self.batchSize]\n",
    "                    tempStorage = tempStorage[self.batchSize:]\n",
    "\n",
    "                data = cacheAdapter.load(1) # load users one by one\n",
    "                data = flatternData(data)\n",
    "                tempStorage.extend(data)\n",
    "\n",
    "                i += 1\n",
    "\n",
    "            except EXP_END_OF_DATA:\n",
    "                break\n",
    "\n",
    "        yield tempStorage\n",
    "\n",
    "def feedProjectsFromCache(manager, batchSize = 32):\n",
    "    cacheFileName = CACHE_FILE_NAME\n",
    "    tempStorage = []\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            while len(tempStorage) >= batchSize:\n",
    "                yield tempStorage[:batchSize]\n",
    "                tempStorage = tempStorage[batchSize:]\n",
    "\n",
    "            manager.cacheAdapter.collectionName = cacheFileName.format(index = i)\n",
    "            data = flatternData(manager.fromCache())\n",
    "            tempStorage.extend(data)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        except EXP_END_OF_DATA:\n",
    "            # no data left\n",
    "            break\n",
    "\n",
    "    yield tempStorage\n",
    "\n",
    "def feedOneByOne(manager):\n",
    "    # will feed preprocessed projects data as TaggedDocument instances one by one\n",
    "    cacheFileName = CACHE_FILE_NAME\n",
    "    tempStorage = [] # stemporary storage for data, that was read from files\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            while len(tempStorage) >= 1:\n",
    "                doc = tempStorage[0]\n",
    "                yield TaggedDocument(words = doc[\"tokens\"], tags = doc[\"tags\"])\n",
    "                tempStorage = tempStorage[1:]\n",
    "\n",
    "            manager.cacheAdapter.collectionName = cacheFileName.format(index = i)\n",
    "            data = flatternData(manager.fromCache())\n",
    "            tempStorage.extend(data)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        except EXP_END_OF_DATA:\n",
    "            # no data left\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "584ed1f5-c3a9-4aa4-8368-22fec165fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = JSONAdapter()\n",
    "ProjectsDatasetManager.usersCollection = usersCollection\n",
    "ProjectsDatasetManager.projectsCollection = projectsCollection\n",
    "manager = ProjectsDatasetManager(25, validate = projectDataIsSufficient, cacheAdapter = adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d2375ea-9300-497e-882a-ce5ca7010e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning user: github:betiol\n",
      "Scanning user: github:DestinyJun\n",
      "Scanning user: github:madf12\n",
      "Scanning user: github:hectorqin\n",
      "Scanning user: github:yaojunguang\n",
      "Scanning user: github:romanofficial\n",
      "Scanning user: github:mikedemarais\n",
      "Scanning user: github:Redseb\n",
      "Scanning user: github:anhquan291\n",
      "Scanning user: github:arfanliaqat\n",
      "Scanning user: github:zhazihong\n",
      "Scanning user: github:xiaomao996688\n",
      "Scanning user: github:FelipeMolinari\n",
      "Scanning user: github:MohamadKh75\n",
      "Scanning user: github:pilotocheg\n",
      "Scanning user: github:TPXP\n",
      "Scanning user: github:gattleung\n",
      "Scanning user: github:872409\n",
      "Scanning user: github:yusufbadurohman\n",
      "Scanning user: github:EQuimper\n",
      "Scanning user: github:neo355\n",
      "Scanning user: github:13627491210\n",
      "Scanning user: github:MikeChugunov\n",
      "Scanning user: github:452MJ\n",
      "Scanning user: github:mohamed-sultan\n",
      "32\n",
      "awesome-code-streamers List of code streamers from multiples plataforms like Twitch, Youtube, etc\n",
      "smart-home-mqtt Experimental and WIP - Bridge between Google Smart Home and MQTT \n",
      "typeorm-seeding A delightful way to seed test data into your database.\n",
      "express-response-formatter :sparkles: Better way to format Express response\n",
      "desafio-rn Desafio React Native\n",
      "command-line-go-ip-servers It will return server names and IPs of a specific server\n",
      "smart-home-mqtt Experimental and WIP - Bridge between Google Smart Home and MQTT \n",
      "rbi-safe 贵州省劳动科学院安全标准化监管系统，基于angular 8.2.9\n",
      "rbi-safe 安全管理平台\n",
      "gtcashapp 贵州高投集团服务区商家收银APP（Android端）基于react-native0.61.2\n",
      "ECMAScript6-study js深入学习\n",
      "rbi-safe-app 贵州省劳动科学院安全标准化监管系统APP（Android端），基于react 16.9.0，react-native 0.61.5\n",
      "react-rbi-website-admin 官网前台管理端，基于react v17.0.1，antd v4.10.3\n",
      "my-react-native-app react-native工程目录包\n",
      "gt-cash 基于VUE的高投服务区商家web端收银系统\n",
      "wx_questionnaire 微信问卷调查后台系统，基于TP3.2.3\n",
      "react-native-study react-native学习\n",
      "typescript-study typescript\n",
      "smart-property-manager 云山智舍管理端\n",
      "gaotou2 贵州高投服务区数据监控系统，基于angular5.2.0\n",
      "webpack-study 手动配置webpack\n",
      "gt-cash-view 贵州高投集团服务区收银商家web客户端，基于vue开发\n",
      "php-study php学习\n",
      "rbi-quote 住房溯源追踪系统，基于Vue.js v2.6.11\n",
      "css3-study css3属性运用demo\n",
      "react-native-file-logger A simple file-logger for React Native with configurable rolling policy, based on CocoaLumberjack on iOS and Logback on Android.\n",
      "react-simple-timefield Simple React time input field\n",
      "ASF-ui The official web interface for ASF\n",
      "class-transformer Decorator-based transformation, serialization, and deserialization between objects and classes. \n",
      "react-native-file-logger A simple file-logger for React Native with configurable rolling policy, based on CocoaLumberjack on iOS and Logback on Android.\n",
      "jitsi-meet Jitsi Meet - Secure, Simple and Scalable Video Conferences that you use as a standalone app or embed in your web application.\n",
      "react-simple-timefield Simple React time input field\n",
      "32\n",
      "vscode-php-helper A php-helper plugin for vscode\n",
      "reader 阅读3服务器版，桌面端，iOS可用。后端 Kotlin + Spring Boot + Vert.x + Coroutine ；前端 Vue.js + Element。麻烦点点star，关注一下公众号【假装大佬】❗️  \n",
      "hyperf 🚀 A coroutine framework that focuses on hyperspeed and flexibility. Building microservice or middleware with ease.\n",
      "z-reader 📘 [vscode插件] 小说阅读器,支持在线搜索和本地阅读,支持txt和epub格式\n",
      "amis 前端低代码框架，通过 JSON 配置就能生成各种页面。\n",
      "ZY-Player ▶️ 跨平台桌面端视频资源播放器.简洁无广告.免费高颜值. 🎞\n",
      "hyperf 🚀A coroutine framework that focuses on hyperspeed and flexibility. Building microservice or middleware with ease.\n",
      "nextra Simple, powerful and flexible site generation framework with everything you love from Next.js.\n",
      "hyper-reorderable-tabs Draggable tabs suport for Hyper Terminal\n",
      "vscode-quick-open Visual Studio Code plugin that provide a quick open file command\n",
      "hectorqin.github.io My blog\n",
      "react-native-rn-videoplayer 基于react-native-video的视频播放器（上下滑动改变音量屏幕亮度，缓存进度，双击暂停等ios Android）\n",
      "antcloud-php-sdk antcloud\n",
      "jsfun-anyproxy Anyproxy for android on JSFun platform\n",
      "nodejs-mobile-react-native Node.js for Mobile Apps React Native plugin\n",
      "ZY-Player ▶️ 跨平台桌面端视频资源播放器.简洁无广告.免费高颜值. 🎞\n",
      "ovine Build entirety admin system ui blazing fast with json.\n",
      "php-resque php-resque for ThinkPHP5/6, ThinkPHP3.2\n",
      "mproxy Simple HTTP Proxy with basic authentication, support simple reverse proxy\n",
      "phpmon 🚀 Hyperf Watch Hot Reload Scripts  😊 Just like nodemon  👉 监听文件变化自动重启Hyperf\n",
      "z-reader 📘 [vscode插件] 小说阅读器,支持在线搜索和本地阅读,支持txt和epub格式\n",
      "hyperf-thinkphp hyperf\n",
      "hyperf-generator hyperf generator\n",
      "hyperterm-overlay A complete and customizable solution for a overlay window in your Hyper.app\n",
      "local-echo A local-echo controller for xterm.js\n",
      "amis 前端低代码框架，通过 JSON 配置就能生成各种后台页面。\n",
      "hyper A terminal built on web technologies\n",
      "react-native-alarm-notification schedule alarm and local notification in react-native\n",
      "react-native-vpn2sock vpn2socks package for react-native. Not support IOS currently.\n",
      "iterm2-scp Iterm2 scp helper script. Use scp command to conveniently upload file to server and download file from server\n",
      "nextra The Next.js Static Site Generator\n",
      "vscode-quick-open Visual Studio Code plugin that provide a quick open file command\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "manager.fromDB()\n",
    "textData = manager.getTextOnly()\n",
    "for text in flatternData(textData):\n",
    "    print(text)\n",
    "    #print(flatternData(data))\n",
    "    #print(text)\n",
    "\"\"\"\n",
    "def feedTextData(manager, batchSize = 1):\n",
    "    tempStorage = []\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            while len(tempStorage) >= batchSize:\n",
    "                if batchSize > 1:\n",
    "                    yield tempStorage[:batchSize]\n",
    "                else:\n",
    "                    yield tempStorage[:batchSize][0] # if I'm requesting only one item per time (training one by one) -> just yield it\n",
    "                tempStorage = tempStorage[batchSize:]\n",
    "\n",
    "            manager.fromDB()\n",
    "            data = flatternData(manager.getTextOnly())\n",
    "            tempStorage.extend(data)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        except EXP_END_OF_DATA:\n",
    "            break\n",
    "\n",
    "    yield tempStorage\n",
    "\n",
    "i = 2\n",
    "for textBatch in feedTextData(manager, 32):\n",
    "    if i <= 0: break\n",
    "    print(len(textBatch))\n",
    "    for text in textBatch:\n",
    "        print(text)\n",
    "    i -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb02703b-a50b-44f5-9845-a3e5a7b451fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache__31-03-2025__(sufficient)_0.json\n",
      "TaggedDocument<['awesome', 'code', 'streamer', 'list', 'code', 'streamer', 'multiple', 'plataforms', 'like', 'twitch', 'youtube'], ['github:lucasfloriani/awesome-code-streamers', 'awesome-code-streamers', '', 'awesome', 'awesome-list', 'lists', 'resources']>\n",
      "TaggedDocument<['smart', 'home', 'mqtt', 'experimental', 'wip', 'bridge', 'google', 'smart', 'home', 'mqtt'], ['github:alvarowolfx/smart-home-mqtt', 'smart-home-mqtt', 'JavaScript']>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 2\n",
    "for item in feedOneByOne(manager):\n",
    "    if i == 0: break\n",
    "    print(item)\n",
    "    i -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f5f4d69-6c5e-432d-91fc-d1573f105b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXP_FEEDER_IS_NONE(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"'Model.corpus' object must be an iterable structure!\")\n",
    "\n",
    "class EXP_MANAGER_IS_NONE(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"'Model.manager' object must be a DatasetManager instance!\")\n",
    "\n",
    "\n",
    "class Model(gensim.models.doc2vec.Doc2Vec):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.corpus = None # corpus is an iterator(iterable function or class object), that will be run with \"for\" loop to extract batches of data\n",
    "        self.manager = None\n",
    "    \n",
    "    def train(self):\n",
    "        # will build vocabulary and train the model on corpus (corpus will be fed by corpus)\n",
    "\n",
    "        if self.corpus == None: raise EXP_FEEDER_IS_NONE\n",
    "        if not isinstance(self.manager, ProjectsDatasetManager) : raise EXP_MANAGER_IS_NONE\n",
    "\n",
    "        self.build_vocab(self.corpus(manager))\n",
    "\n",
    "        super().train(self.corpus(manager), total_examples=self.corpus_count, epochs=self.epochs)\n",
    "\n",
    "    def assess(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82a60326-ef2e-46e5-b3bc-15f192b58925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndocumentsCorpus = []\\n\\nfor project in manager.data:\\n    documentsCorpus.append(TaggedDocument(words=project[\"tokens\"], tags=project[\"tags\"]))\\n\\ndocumentsCorpus\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "documentsCorpus = []\n",
    "\n",
    "for project in manager.data:\n",
    "    documentsCorpus.append(TaggedDocument(words=project[\"tokens\"], tags=project[\"tags\"]))\n",
    "\n",
    "documentsCorpus\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9150ae5-5a1a-4edb-be81-93c16fa102be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache__31-03-2025__(sufficient)_0.json\n",
      "cache__31-03-2025__(sufficient)_1.json\n",
      "cache__31-03-2025__(sufficient)_2.json\n",
      "cache__31-03-2025__(sufficient)_3.json\n",
      "cache__31-03-2025__(sufficient)_4.json\n",
      "cache__31-03-2025__(sufficient)_5.json\n",
      "cache__31-03-2025__(sufficient)_6.json\n",
      "cache__31-03-2025__(sufficient)_7.json\n",
      "cache__31-03-2025__(sufficient)_8.json\n",
      "cache__31-03-2025__(sufficient)_9.json\n",
      "cache__31-03-2025__(sufficient)_10.json\n",
      "cache__31-03-2025__(sufficient)_11.json\n",
      "cache__31-03-2025__(sufficient)_12.json\n",
      "cache__31-03-2025__(sufficient)_13.json\n",
      "cache__31-03-2025__(sufficient)_14.json\n",
      "cache__31-03-2025__(sufficient)_15.json\n",
      "cache__31-03-2025__(sufficient)_16.json\n",
      "cache__31-03-2025__(sufficient)_17.json\n",
      "cache__31-03-2025__(sufficient)_18.json\n",
      "cache__31-03-2025__(sufficient)_19.json\n",
      "cache__31-03-2025__(sufficient)_20.json\n",
      "cache__31-03-2025__(sufficient)_21.json\n",
      "cache__31-03-2025__(sufficient)_22.json\n",
      "cache__31-03-2025__(sufficient)_23.json\n",
      "cache__31-03-2025__(sufficient)_24.json\n",
      "cache__31-03-2025__(sufficient)_25.json\n",
      "cache__31-03-2025__(sufficient)_26.json\n",
      "cache__31-03-2025__(sufficient)_27.json\n",
      "cache__31-03-2025__(sufficient)_28.json\n",
      "cache__31-03-2025__(sufficient)_29.json\n",
      "cache__31-03-2025__(sufficient)_30.json\n",
      "cache__31-03-2025__(sufficient)_31.json\n",
      "cache__31-03-2025__(sufficient)_32.json\n",
      "cache__31-03-2025__(sufficient)_33.json\n",
      "cache__31-03-2025__(sufficient)_34.json\n",
      "cache__31-03-2025__(sufficient)_35.json\n",
      "cache__31-03-2025__(sufficient)_36.json\n",
      "cache__31-03-2025__(sufficient)_37.json\n",
      "cache__31-03-2025__(sufficient)_38.json\n",
      "cache__31-03-2025__(sufficient)_39.json\n",
      "cache__31-03-2025__(sufficient)_40.json\n",
      "cache__31-03-2025__(sufficient)_41.json\n",
      "cache__31-03-2025__(sufficient)_42.json\n",
      "cache__31-03-2025__(sufficient)_43.json\n",
      "cache__31-03-2025__(sufficient)_44.json\n",
      "cache__31-03-2025__(sufficient)_45.json\n",
      "cache__31-03-2025__(sufficient)_46.json\n",
      "cache__31-03-2025__(sufficient)_47.json\n",
      "cache__31-03-2025__(sufficient)_48.json\n",
      "cache__31-03-2025__(sufficient)_49.json\n",
      "cache__31-03-2025__(sufficient)_50.json\n",
      "cache__31-03-2025__(sufficient)_51.json\n",
      "cache__31-03-2025__(sufficient)_52.json\n",
      "cache__31-03-2025__(sufficient)_53.json\n",
      "cache__31-03-2025__(sufficient)_54.json\n",
      "cache__31-03-2025__(sufficient)_55.json\n",
      "cache__31-03-2025__(sufficient)_56.json\n",
      "cache__31-03-2025__(sufficient)_57.json\n",
      "cache__31-03-2025__(sufficient)_58.json\n",
      "cache__31-03-2025__(sufficient)_59.json\n",
      "cache__31-03-2025__(sufficient)_60.json\n",
      "cache__31-03-2025__(sufficient)_61.json\n",
      "cache__31-03-2025__(sufficient)_62.json\n",
      "cache__31-03-2025__(sufficient)_63.json\n",
      "cache__31-03-2025__(sufficient)_64.json\n",
      "cache__31-03-2025__(sufficient)_65.json\n",
      "cache__31-03-2025__(sufficient)_66.json\n",
      "cache__31-03-2025__(sufficient)_67.json\n",
      "cache__31-03-2025__(sufficient)_68.json\n",
      "cache__31-03-2025__(sufficient)_69.json\n",
      "cache__31-03-2025__(sufficient)_70.json\n",
      "cache__31-03-2025__(sufficient)_71.json\n",
      "cache__31-03-2025__(sufficient)_72.json\n",
      "cache__31-03-2025__(sufficient)_73.json\n",
      "cache__31-03-2025__(sufficient)_74.json\n",
      "cache__31-03-2025__(sufficient)_75.json\n",
      "cache__31-03-2025__(sufficient)_76.json\n",
      "cache__31-03-2025__(sufficient)_77.json\n",
      "cache__31-03-2025__(sufficient)_78.json\n",
      "cache__31-03-2025__(sufficient)_79.json\n",
      "cache__31-03-2025__(sufficient)_80.json\n",
      "cache__31-03-2025__(sufficient)_81.json\n",
      "cache__31-03-2025__(sufficient)_82.json\n",
      "cache__31-03-2025__(sufficient)_83.json\n",
      "cache__31-03-2025__(sufficient)_84.json\n",
      "cache__31-03-2025__(sufficient)_85.json\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Using a generator as corpus_iterable can't support 6 passes. Try a re-iterable sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcorpus \u001b[38;5;241m=\u001b[39m feedOneByOne\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mmanager \u001b[38;5;241m=\u001b[39m manager\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#model.build_vocab(documentsCorpus)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#model.train(documentsCorpus, total_examples = model.corpus_count, epochs = model.epochs)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 24\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanager, ProjectsDatasetManager) : \u001b[38;5;28;01mraise\u001b[39;00m EXP_MANAGER_IS_NONE\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_vocab(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus(manager))\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/gensim/models/doc2vec.py:516\u001b[0m, in \u001b[0;36mDoc2Vec.train\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m offsets\n\u001b[1;32m    514\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_doctags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m start_doctags\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDoc2Vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mword_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/gensim/models/word2vec.py:1046\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m=\u001b[39m epochs\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_training_sanity(epochs\u001b[38;5;241m=\u001b[39mepochs, total_examples\u001b[38;5;241m=\u001b[39mtotal_examples, total_words\u001b[38;5;241m=\u001b[39mtotal_words)\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_corpus_sanity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1050\u001b[0m     msg\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     ),\n\u001b[1;32m   1055\u001b[0m )\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss \u001b[38;5;241m=\u001b[39m compute_loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/gensim/models/word2vec.py:1506\u001b[0m, in \u001b[0;36mWord2Vec._check_corpus_sanity\u001b[0;34m(self, corpus_iterable, corpus_file, passes)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe corpus_iterable must be an iterable of lists of strings, got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m corpus_iterable)\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(corpus_iterable, GeneratorType) \u001b[38;5;129;01mand\u001b[39;00m passes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1507\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a generator as corpus_iterable can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passes. Try a re-iterable sequence.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1510\u001b[0m     _, corpus_ext \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(corpus_file)\n",
      "\u001b[0;31mTypeError\u001b[0m: Using a generator as corpus_iterable can't support 6 passes. Try a re-iterable sequence."
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "\n",
    "VECTOR_SIZE = 100\n",
    "EPOCH_NUMBER = 6\n",
    "WORD_MIN_AMOUNT = 3\n",
    "WINDOW_SIZE = 7\n",
    "\n",
    "model = Model(vector_size = VECTOR_SIZE, window = WINDOW_SIZE, min_count = WORD_MIN_AMOUNT, epochs = EPOCH_NUMBER)\n",
    "model.corpus = feedOneByOne\n",
    "model.manager = manager\n",
    "model.train()\n",
    "print(model.epochs)\n",
    "#model.build_vocab(documentsCorpus)\n",
    "#model.train(documentsCorpus, total_examples = model.corpus_count, epochs = model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab2f6a-599d-4f6d-9a52-ef8ff174f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model.infer_vector(['awesome', 'code', 'streamer', 'list', 'code', 'streamer', 'multiple', 'plataforms', 'like', 'twitch', 'youtube'])\n",
    "vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
